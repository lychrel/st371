\documentclass[10pt]{extarticle}
\usepackage[T1]{fontenc}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}

% table spacing
\usepackage{setspace}

%% zero set
\usepackage{amssymb}

% plum
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}

%% Sets page size and margins
\usepackage[letterpaper,top=0.5cm,bottom=0.5cm,left=0.5cm,right=0.5cm,marginparwidth=0.25cm]{geometry}

%% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

% for compact, wrappable table
%\usepackage{showframe}% http://ctan.org/pkg/showframe
%\usepackage{booktabs}% http://ctan.org/pkg/booktabs
\usepackage{wrapfig,lipsum,booktabs}
\setlength{\textfloatsep}{0.1cm}

% distribution
\newcommand{\dist}[3]{${#1}\mathtt{\sim}${#2}(${#3})$}

%% red bold text
\newcommand{\re}[1]{\textcolor{red}{\textbf{#1}}}

%% blue text
\newcommand{\bt}[1]{\textcolor{blue}{#1}}
%% blue normal text

% purple bold text
\newcommand{\pu}[1]{\textcolor{violet}{\textbf{#1}}}
% purple text
\newcommand{\pr}[1]{\textcolor{violet}{#1}}

%% pink bold text
\newcommand{\pute}[1]{\textcolor{pink}{\oldtextbf{#1}}}

\begin{document}
	\begin{wraptable}{l}{16cm}
		\begin{tabular}{c c c c c}
			 & \re{Distro} & \re{E(X)} & \re{V(X)} & \re{pmf} \\
			% \hline \\
			% BINOMIAL
			Binomial (discrete) &
			$X\mathtt{\sim}$Bin$(n,p)$ &
			$np$ &
			$np(1-p)$ &
			${n \choose x}p^{x}(1-p)^{n-x}$ \\
			% HYPERGEO
			Hypergeo (discrete) &
			$X\mathtt{\sim}$Hyper$(n,M,N)$ &
			$n\cdot\frac{M}{N}$ &
			\re{$\Big(\frac{N-n}{N-1}\Big)\cdot n \cdot \frac{M}{N}\cdot\Big(1 - \frac{M}{N}\Big)$} &
			\bt{$\frac{{M\choose x}{N-M \choose n-x}}{{N\choose n}}$} \\
			% NEGBIN
			NegBin (discrete) &
			$X\mathtt{\sim}$NegBin$(r,p)$ &
			$\frac{r(1-p)}{p}$ &
			$\frac{r(1-p)}{p^{2}}$ &
			${x+r-1 \choose r-1}p^{r}(1-p)^{x}$ \\
			% POISSON
			Poisson (discrete) &
			$X\mathtt{\sim}$Poi$(\mu)$ &
			$\mu$ &
			$\mu$ &
			\bt{$\frac{e^{-\mu}\cdot\mu^{x}}{x!}$} \\
			\hline
		\end{tabular}
	\end{wraptable}
	\noindent 
	\re{${n \choose k}$} $= \frac{n!}{r!(n-r)!} =$ ``n choose k''$=$ num combos of size $r$ that can be formed from $n$ indiv's in group
	\re{conditions for Bin} \bt{(1)} Two possible outcomes of each trial: S (what we counting) or
	F (all else). \bt{(2)} num trials $n$ is \emph{known and fixed} \bt{(3)} outcomes are
	\emph{independent} from one trial to others \bt{(4)} $p(\text{success})$ is \emph{same for all
	trials} \bt{(\textbf{$\cdot$})} if conditions met, $X={\text{num S's}}$ is binomial RV w/ params
	\re{n} number of trials / sample size and \re{p} probability of success.
	% CUT RANDOM INSIGHT INTO V(X)
	% \re{V(X)} of bin dist is largest (given $n$) when $p=0.5$ because \emph{the outcome is hardest to
	% predict!}
	% CUT BIN EXAMPLE 1
	%\re{ex1} suppose $p=0.7$. How does $P(X=x)$ change? Since $p(S)$ went up, more successful
	%outcomes; probabilities would shift towards largue values of $X$. Expect 2--3 S's to be most
	%likely X-val since $70\%$ of 3 is between (2,3).
	% CUT BIN EXAMPLE 2
	%\re{ex2} $10\%$ Americans left-handed. $X=$ num $\ell$-handed Americans in random sample of 12.
	%$X\mathtt{\sim}$Bin$(n,p)$ with $(n,p)=(12,0.1)$.
	%\bt{(i)} mean val $=\mu=E(X)=np=1.2$ expected
	%$\ell$-hand people in sample of 12.
	%\bt{(ii)} SD $=\sigma=\sqrt{V}=\sqrt{np(1-p)}=1.04$ $\ell$-hand
	%people. Roughly, poss vals X will be about 1.04 people from mean val of 1.2. 
	%\bt{(iii)} prob that sample contains at most 2 $\ell$-hand Americans is
	%$P(X\leq 2)=P(X=0)+\ldots+P(X=2)=0.889$, so $88.9\% $ chance of finding 2 or fewer $\ell$-hand
	%people in 12-American sample
	\re{conditions for HyperG} when sampling \emph{without replacement} from a small population
	(population not at least $10\times$ sample size).
	\bt{(1)} pop is finite, consists of \re{N} individuals/objects
	\bt{(2)} 2 kinds of indivs/objs: success (S), failure (F); \emph{and there are} \re{M}$<N$
	successes in population
	\bt{(3)} a sample of \re{n} individuals are \emph{randomly selected without replacement}
	\bt{(\textbf{$\cdot$})} if conditions met, $X={\text{num S's}}$ is hypergeom rv
	% OPTIONAL
	\re{pmf explained} numerator: num ways to have $x$ successes \& $n-x$ failues.
	Denominator: num ways to select a subset of $n$ indivs/objs out of group of $N$
	\re{Finite Pop Correction Factor$=$} $1-[\frac{n-1}{N-1}]$, second term is proportion of population
	included in sample.
	% OPTIONAL
	Since $<1$, hyperG has \emph{smaller V(X)} than bin.
	% Contract example (5.19)
	\re{conditions for NegBin}
	\bt{(1)} exp consists of \emph{potentially infinite num of indep Bernoulli trials}
	\bt{(2)} two poss outcomes for each trial: S, F
	\bt{(3)} probability of success \re{p} is \emph{same for all trials}
	\bt{(4)} exp continues until a total of \re{r} successes have been observed, where $r$ is fixed
	int $>0$
	\bt{(\textbf{$\cdot$})} if conditions met, $X={\text{num fails before $r$th success}}$ is
	negbin rv dist dependent on r,p
	\re{Geom dist} special case of NegBin where $r=1$
	% CONSIDER CUTTING 
	\re{$P(12\leq X\leq 28) =$} $P(11<X<29)=P(X=12)+\ldots+P(X=28)$
	\re{Continuous RVs} change: \emph{integration} instead of summation is now used to calculate
	probs, E's, V's. Also, \underline{CDF's} play more central role in finding probs,
	\emph{percentiles}
	\re{conditions for continuity} $X$ is continuous if
	\bt{(i)} $X$ can be any value in an intrvl,
	such as [0,1] or even (-$\infty$,$\infty$), or union of disjoint intrvls, \underline{AND}
	\bt{(ii)} $P(X=c)=0$ for any possible val of $c$---i.e., no indiv. val of $X$ has a positive
	probability
	\bt{\textbf{($\cdot$)}} CRV's often used to represent measurements
	\re{Probability Density Funciton (pdf)} $f(x)$ defines shape of a continuous distro. Needs to
	be integrated to find probabilities. Has prop that, for a crv $X$ has property that, for any two
	constants $a,b$:
	\re{$P(a\leq X\leq b)$} = $\int_{a}^{b}f(x)dx$
	\re{pdf criteria}
	\bt{(1)} $f(x)$ is \emph{non-negative}: $f(x)\geq 0$ for all -$\infty<x<\infty$
	\bt{(2)} entire area under $f(x)$ is 1: $\int_{-\infty}^{\infty}f(x)dx = 1$
	\re{P($X\leq 0.5$)} $= \int_{a}^{0.5}f(x)dx$
	\re{Uniform Dist}
	$f(x)=\frac{1}{b-a}$ for $a\leq x \leq b$, $0$ otherwise (issa square wave)
	\re{Cumulative Distribution Function (cdf)}: the cdf $F(x)$ of a crv $X$ is
	\re{$F(x)$} $=P(X\leq x) = \int_{-\infty}^{x}f(y)dy$
	\re{cdf of uniform dist} $F(x) = \int_{a}^{x}\frac{1}{b-a}dy = \frac{x-a}{b-a} \leftarrow$
	straight line w/ $F(a)=0,F(b)=1$ and slope $1/(b-a)$
	\re{CDF Propositions} if $X$ is a crv with pdf $f(x)$ and cdf $F(x)$, $a,b$ any two numbers
	s.t. $a<b$, then
	\bt{(1)} \re{$P(X>a)$} $= 1-F(a)$
	\bt{(2)} \re{$P(a\leq X\leq b)$} $=F(b) - F(a)$
	\bt{(3)} \re{$P(X=x)$} $=0$ for all values of $x$. Resultantly,
	\b{(3.i)} $P(A\leq X\leq b) = P(a<X\leq b) = P(a\leq X < b) = P(a<X<b)$
	\bt{(4)} $f(x)$ is the derivative of $F(X)$: $f(x) = \frac{dF(x)}{dx}$
	\re{Expected value of $X$, $\mu_{X}=E(X)=$} $\int_{x}x\cdot f(x)dx$
	\re{Expected value of function, $\mu_{h(X)}=E(h(x))=$} $\int_{x}h(x)\cdot f(x)dx$
	\re{Variance of X, $\sigma_{X}^{2}=$} $V(X) = \int_{x}(x-\mu)^{2}\cdot f(x)dx
												= E(X^{2}) - [E(X)]^{2}$
	\re{Standard Deviation of X, $\sigma_{X}=$} $\sqrt{V(X)}$
	% E(X) uniform dist, 6.50
	\re{Percentile} for any continuous rv $X$, and for values of $p$ $(0<p<1)$, the
	$(100p)^{th}$ percentile, $\eta(p)$, of dist $X$ is defined by
	\re{$p = F(\eta(p))=$} $\int_{-\infty}^{\eta(p)}f(y)dy$
	\re{notes on percentile} $\eta(p)$ is the val in the distribution of $X$ s.t.
	$100p\%$ of area under density curve lies to the left of $\eta(p)$ and
	$100(1-p)\%$ lies to the right of $\eta(p)$.
	\re{to find $p^{th}$ percentile of any dist:} set $p$ equal to the cdf and solve
	for $x$!
	\re{Median $\tilde\mu$ of $X$} for any crv $X$, the median is the \emph{$50^{th}$
	percentile} of the dist $X$, s.t. $\tilde\mu$ satisfies $0.5=F(\tilde\mu)$. Half
	of area under density curve lies to left of $\tilde\mu$, and half to right.
	\re{mean vs median} median is middle val, won't be affected by outlier values.
	However, mean \emph{will} be affected. If distribution is right-skewed,
	median $<$ mean; if left-skewed, mean $<$ median
	\re{Normal (Gaussian) Dist, $X\mathtt{\sim}$N$(\mu,\sigma^{2})$} most common family; many rv's have (approx) normal dist,
	and if they don't, ther mean often does. Most large-sampling statistic inference
	relies upon normal distribution.
	\re{Normal pdf} a crv $X$ has a normal distribution w/ parameters $\mu$ and $\sigma$
	(or $\mu$ and $\sigma^{2}$) if pdf of $X$ is
	\re{$f(\mu,\sigma)=$} $\frac{1}{\sqrt{2\pi}\sigma}e^{-(x-\mu)^{2}/(2\sigma^{2})}$
	\re{notes on normal dist}
	\bt{(1)} $x$ can take any vals $-\infty<x<\infty$
	\bt{(2)} $\mu$ (although fixed) can take any vals $-\infty<x<\infty$
	\bt{(2.1)} $\mu$ is the \emph{mean} of the normal dist; this controls center of
	distribution
	\bt{(3)} $\sigma$ can take any vals $\sigma>0$
	\bt{(3.1)} $\sigma$ is the \emph{standard deviation} of the normal dist
	($\sigma^{2}$ is the variance); this controls the spread/scale of the dist
	\bt{($\cdot$)} normal dist always has bell shape
	% sketching a normal dist 7.6
	\re{sketching a normal dist}
	\bt{(i)} curve is tallest at $\mu$, at center
	\bt{(ii)} 99.7$\%$ of dist is between $\mu-3\sigma$ and $\mu+3\sigma$. These are
	the approx. smallest and largest vals of $X$
	\bt{(iii)} changing $\mu$ shifts entire distribution
	\bt{(iv)} changing $\sigma$ controls how tall/flat dist is
	\re{standard score z$=$} $\frac{x-\mu}{\sigma}$ tells you how many \emph{standard
	deviations} a particular observation is from mean. Dist from mean relative to how
	much \emph{variation} there is. Follows a \emph{standard normal distribution}
	\re{standard normal distribution} a crv $Z$ is said to have a \emph{standard
	normal distribution} if \bt{$\mu=0$} and \bt{$\sigma=1$}:
	$Z\mathtt{\sim}$N$(0,1)$
	\re{pdf Z $=$} $f(z;0,1) = \frac{1}{\sqrt{2\pi}}e^{-z^{2}/2}$
	\re{cdf Z $\Phi(z)=$} $P(Z\leq z) = \int_{-\infty}^{z}f(y;0,1)dy$
	\re{can find probabilities by}
	\bt{(1)} integrating the pdf $f(x)$, so $P(a<X<b) = \int_{b}^{a}f(x)dx$
	\bt{(2)} plugging values into cdf $F(x)$, so $P(a<x<b)=F(b)-F(a)$
	\re{finding probabilities using a normal dist}
	\bt{(i)} integrals must be
	approximated; difficult before computers were available
	\bt{(ii)} lots of possible normal distributions
	\bt{(iii)} soluiton (then): ``standardize'' each normal dist using standard score;
	get probabilities from table
	\bt{(iv)} solution (now): computing power
	\re{two ways to calc probabilities for a normal dist:}
	\bt{(1)} use table A3 in appendix, which gives values for $\Phi(z)$
	\bt{(2)} use graphing calc
	\re{e.g.} for $Z\mathtt{\sim}$N$(0,1)$, P($Z < -1.37$) $=\Phi(-1.37)$, so nav to
	row $z=-1.3$ and col $z=0.07$ and it's there
	\re{for greater-thans:} table only gives CDF$=P(Z<z)$. To find $P(Z>z)$, need to
	subtract prob provided by table from 1
	\re{inequalities} $P(-2<Z<2) = \Phi(2) - \Phi(-2)$ (see \bt{pic 1, pic 3})
	% img here for wierder example 
	\re{calc} TI-83:
	$2^{nd}\rightarrow$VARS$\rightarrow$2:normalcdf(LB,UB,$\mu$,$\sigma$). if one of
	bounds is infinity, enter really big (/small) number. to find \bt{percentile} via
	calc, use invNorm func.
	\re{un-standardizing a table val} $x=z\cdot \sigma + \mu$
	\re{standardizing a probability} see \bt{pic 2, pic 4}
	\re{Normal approx. to Bin} $X\mathtt{\sim}$Bin$(n,p)$ can be written as
	$X=X_{1}+\ldots+X_{n}$
	\re{Central Limit Thm:} This $X$ is approximately normal or
	\re{$Z=\frac{X-np}{\sqrt{npq}}$} is approx standard normal $N(0,1)$ as
	$n\rightarrow\infty$. Good approx even if $n$ moderate ($\approx$30) and
	$np\geq5$ and $n(1-p)\geq 5$
	\re{Standardizing Normal Dists} if not standard normal dist, you'll have to
	standardize X val before using table
	\re{$B(n,p)\approx N(np,npq)$}
	\re{ex} $X\mathtt{\sim}$Bin$(n=15,p=0.4)$, $Y\mathtt{\sim}$N$(np,npq)=$N$(6,3.6)$
	then $P(X=5)\approx P(4.5<Y<5.5) =
	P(\frac{4.5-6}{\sqrt{3.6}} < P(\frac{Y-6}{\sqrt{3.6}}
							   < P(\frac{5.5-6}{\sqrt{3.6}})
							   		 = P(Z<-0.2635) - P(Z<-0.7906)
									 = 0.1815$, while exact $P(X=5)=0.1859$
	\re{Gamma function $\Gamma (\alpha)$}
	\bt{(1)} for any $\alpha>1$, $\Gamma (\alpha)
	= (\alpha - 1)\Gamma(\alpha - 1)$.
	\bt{(2)} For any positive int $n$, $\Gamma(n) = (n-1)!$
	\bt{(3)} $\Gamma(1/2) = \sqrt{(\pi)}$
	\re{Gamma Distribution $X\mathtt{\sim}$Gamma$(\alpha,\beta)$} \emph{not} the gamma
	function!!! Often used for \emph{waiting times} or \emph{survival times}
	\re{Gamma PDF} $f(x;\alpha,\beta)
					= \frac{x^{\alpha-1}e^{-x/\beta}}{\beta^{\alpha}\Gamma(\alpha)}$
	\re{Gamma CDF} $F\Big(\frac{x}{\beta}; \alpha\Big)
					 = \int_{0}^{x/\beta}\frac{y^{\alpha - 1}e^{-y}}{\Gamma(\alpha)}dy$
					 (probabilities found via a table)
	\re{Gamma E(X)} $=\alpha\beta$
	\re{Gamma V(X)} $=\sigma^{2}=\alpha\beta^{2}$
	\re{Gamma props}
	\bt{(1)} $x$ can only take non-neg vals: $x\geq 0$
	\bt{(2)} $\beta$ can only take pos vals: $\beta > 0$. $\beta$ is the \emph{scale}
	parameter; it controls \emph{spread} of dist. When $\beta=1$, $X$ is a
	\pr{\emph{standard} gamma dist}: $f(x;\alpha)=\frac{x^{\alpha-1}e^{-x}}{\Gamma(\alpha)}$
	\re{Gamma prob} $P(X<6)=F(6/1;3)$ go to table A4, look for col $\alpha=3$ and down
	to row $X=6$. $P(2<X<5)=F(5/1;3)-F(2/1;3)$
	\re{Standardizing Gamma Dists} if $\beta\neq 1$, standardize X val before looking
	it up in table. e.g., for G(4,5), $P(X<8) = F(8/5;4) = F(1.6;4)$, make
	inequality: $F(1;4) < F(1.6;4) < F(2;4) \rightarrow 0.019 < P(X<8) < 0.143$
	\re{Special cases of Gamma dist}
	\bt{(i)} when $\alpha=1$ and $\beta>0$, gamma dist is
	the \bt{Exponential} dist w/ parameter $\beta$
	\bt{(ii)} when $\alpha=v/2$ and $\beta=2$, for pos int $v$, gamma dist is
	\emph{Chi-square} dist w/ param $v$---common dist for stat inference
	\re{Exponential Dist $X\mathtt{\sim}$Exp$(\lambda)$} special case of gamma dist.
	$x$ is non-neg, $\lambda$ is positive. Gen. skewed to right
	\re{Exponential PDF} $f(x;\lambda) = \lambda e^{-\lambda x}$
	\re{Exponential CDF} $F(x) = 1-e^{-\lambda x}$
	\re{Exponential $E(X)$} $= \frac{1}{\lambda}$
	\re{Exponential $V(X)$} $= \frac{1}{\lambda^{2}}$
	\re{hazard rate $\lambda$} higher value of $\lambda$ means shorter survival times.
	``Waiting time'' could also represent length of time between sucsesses of a
	\emph{Poisson} rv
	\re{notes Exp}
	\bt{(i)} sum of $\alpha$ pos independent Exp($\beta$) rv's can be modeled by
	the \bt{Gamma($\alpha, \beta$)} dist
	\bt{(ii)} exp dist is said to be \emph{memoryless}, i.e. $P(X>t+s/X>t)=P(X>s)$
	\bt{(iii)} gamma and other dists don't have this property
	\re{system of comopnents} each component lifetime $\mathtt{\sim}$Exp(0.01),
	component failures are independent, $A_{i}=$ith component lasts at least $t$ hours,
	and $X=$ time at which sys fails. Compute cdf $X$: $F(t) = P(X\leq t)$.
	Start by finding $P(X>t)$: $X>t \Leftrightarrow A_{1}\cap A_{2} \cap A_{3} \cap
	A_{4}$, so $P(X>t)=P(A_{1})\cdots P(A_{4}) = P(Y_{1}>t)\cdots P(Y_{4}>t)$ where
	$Y_{i}=$ lifetime of component $i$. Note cdf $Y_{i}$ is $P(Y_{i}\leq t)
	= (1 - e^{-0.01t})$, so $P(Y_{i} > t)$ is 1 minus that  $=e^{-0.01t}$. Then 
	$P(X>t) = e^{-0.04t} \Rightarrow F(t) = P(X\leq t) = 1 - e^{-0.04t}$, which is
	$X\mathtt{\sim}$Exp$(0.04)$
	\re{other exs} lifebulb follows exp dist; expected lifetime $1,000$ hrs.
	Prob rand-select bulb will last $>2,000$ hrs is, since we can get $\lambda=0.001$
	from $E(X)$, $P(X>2000) = 1 - F(2000;0.001) = e^{-(0.001)(2000)} = 0.135$
	\pu{practice probs}
	\re{NegBin ex} An expert sharpshooter misses a target 5\% of the time. Let X = {the number of
		shots that hit the target before the second miss}. What is the probability that she misses
		the target
		for the second time on the fifteenth shot? How many shots would you expect to hit the
		target before the second miss? How many shots would you expect her to take before the
		second miss?
	\pr{NegBin ex} \dist{X}{NegBin}{r=2,p=0.05}, so
		\pr{(a)} required prob = $P(X=15-r=13)$ =
			${14 \choose 1}p^{2}(1-p)^{13}=14\cdot 0.05^{2}\cdot 0.95^{13}=0.018$
		\pr{(b)} $E(X)=\frac{r(1-p)}{p}=\frac{2(1-0.05)}{0.05}=38$
		\pr{(c)} $E(X)+2=40$
	\re{HyperGeo ex} Among 16 applicants for a job, 11 have college degrees. Suppose that 4 of
		these applicants will be randomly selected for an interview. Let X = {the number of
		selected applicants who have a college degree}. What is the distribution of X? What is the
		probability that at least 1 of the applicants has a college degree?
	\pr{HyperGeo ex}
			\pr{(a)} \dist{X}{hypergeo}{N=16,M=11,n=4}
			\pr{(b)} $P(X\geq 1) = 1-P(X=0) = 1 - {11 \choose 0}{5 \choose 4}/{16 \choose 4}
			= 1 - \frac{5}{1820} = 0.9973$
			\pr{(c)}
	\re{Poisson ex} Suppose that earthquakes occur in the western portion of the United States at
		an average rate of 2 per week. Let X = {the number of earthquakes that occur in the western
		portion of the United States in a week}. What is the probability that at most 1 earthquake
		occurs during the next week?
	\pr{Poisson ex}
			\pr{($\cdot$)} \dist{X}{Poisson}{\mu=2}, so $P(X\leq 1)
			= P(X=0)+P(X=1)=\frac{\mu^{0}e^{-\mu}}{0!}+\frac{\mu^{1}e^{-\mu}}{1!}=(1+2)e^{-2}=0.406$
	\re{Normal ex} In a photographic process, the developing time of prints may be looked upon as a
		normal random variable with a mean of 18 seconds and a standard deviation of 1.2 seconds.
		What is the probability that it takes between 15.9 and 19.3 seconds to develop a print?
		Fill in the blank: 85\% of all prints are developed in \_\_\_ seconds or less. 
	\pr{Normal ex}
		\pr{($\cdot$)} $X=$developing time$\mathtt{\sim}$Normal$(\mu=18~sec, \sigma=1.2~sec)$,
		so
		\pr{(a)} $P(15.9\leq X\leq 19.3) = P(-1.75\leq Z\leq 1.08) = 0.82$, where we standardized
		by plugging in $Z=\frac{(X-\mu)}{\sigma}$ for both bounding X-vals and, in the midde, in
		the general case.
		\pr{(b)} 85 percentile from $N(0,1)$ is 1.04, so required number is
		$18+1.04\cdot 1.2=19.25~seconds$
	\re{Uniform ex} The time taken to deliver a pizza follows a uniform distribution from 20
		minutes to 60 minutes. What is the probability that the time to deliver a pizza is at least
		25 minutes? What is the 55th percentile of this distribution?
	\pr{Uniform ex}
		\pr{(a)} \dist{X}{Uniform}{20,60}, so $P(X\geq 25) = (60-25)/(60-20) = 0.875$
		\pr{(b)} $(x-20)/(60-20) = 0.55 \Rightarrow x=42$ minutes
	\re{Exponential ex} The lifetime of a certain type of car (in thousands of miles) has an
		Exponential Distribution with $\lambda = 0.01$. What is the probability that a car of this
		type last for more than 90,000 miles?
	\pr{Exponential ex}
		\pr{(a)} \dist{X}{exp}{\lambda=0.01}, so $P(X>90)=e^{-90\lambda}=e^{-0.9}=0.4066$
	\re{Binomial ex} The College Board reports that 2\% of the 2 million high school students who
		take the SAT each year receive special accommodations because of documented disabilities
		(Los Angeles Times, July 16, 2002). Consider a random sample of 25 students who have
		recently taken the test.
	\pr{Binomial ex}
		\pr{(a)} $P(X=1)={25 \choose 1}p^{1}(1-p)^{25-1}=25\cdot 0.02\cdot (1-0.02)^{24}=0.3079$
		\pr{(b)} $P(X\geq 1)=1-P(X=0)=1-(1-0.02)^{25}=0.3965$
		\pr{(c)} $P(X\geq 2)=1-P(X\leq 1)= 1 - (P(X=0)+P(X=1))=1 - (0.6034+0.3079) = 0.3079$
		\pr{(d)} $\mu = np = 25\times 0.02 = 0.5$, $\sigma=\sqrt{np(1-p)} = \sqrt{25\times 0.02
			\times (1-0.02)} = 0.7,$ so $P(\mu - 2\sigma \leq X \leq \mu+2\sigma)
			= P(-0.9\leq X \leq 1.9) = P(X\leq 1) = 0.9113$
		\pr{(e)} Y = hours a randomly selected student is allowed. Then Y takes 4.5 with
			prob=0.02 and 3 with prob=0.98. $E(Y)=4.5\cdot 0.02 + 3\cdot 0.98=3.03~hours$
	\re{Binomial Func ex} A toll bridge charges \$1.00 for passenger cars and \$2.50 for other
		vehicles. Suppose that during daytime hours, 60\% of all vehicles are passenger cars. If 25
		vehicles cross the bridge during a particular daytime period, what is the resulting
		expected toll revenue? (Hint: Let X $=$ the number of passenger cars; then the toll revenue
		h(X) is a linear function of X.)
	\pr{Binomial Fun ex}
		\pr{{($\cdot$)}} $X=$ \# of passenger cars out of $n=25$. Then \dist{X}{Bin}{n=25,p=0.6}. 
			The toll $Y=X+2.5(n-X)$, so $E(Y)=E(X)+2.5(n-E(X))=np+2.5(n-np)=15+2.5(25-15)=$\$40
	\re{cdf ex} The weekly demand for propane gas (in 1000s of gallons) from a particular
	facility is an rv $X$ with pdf $f(x) = 2(1-\frac{1}{x^{2}})$, $1\leq x \leq 2$, $0$ otherwise.
	(a) Compute the cdf of X, (b) Obtain an expression for (100p)th percentile. What is the value
	of $\tilde\mu$? (c) Compute E(X) and V(X). (d) If 1.5 thousand gallons are in stock at the
	beginning of the week and no new supply is due in during the week, how much of the 1.5
	thousand gallons is expected to be left at the end of the week? (\emph{Hint}: let h(x)=amount
	left when demand = x)
	\pr{cdf ex}
		\pr{(a)} $F(X)=0$ for $x<1$ and $F(x)=1$ for $x>2$. For $x$ in [1,2], $F(x)$ is equal to
			$F(x) = \int_{1}^{x} 2(1-\frac{1}{y^{2}})dy = 2(x-2+x^{-1})$
		\pr{(b)} Solve $2(x-2+x^{-1})=p$ for $x$ in $(1,2) \Rightarrow x=(4+p+\sqrt{p^{2}+8p})/4$,
			 so set $p=0.5 \Rightarrow \mu = (4.5+\sqrt{4.5})/4 = 1.64$
		\pr{(c)} $E(X) = \int_{1}^{2} 2x (1-x^{-2})dx = \int_{1}^{2} 2xdx
			- 2\int_{1}^{2}x^{-1}dx = x^{2}|_{1}^{2} - 2\ln{(x)}|_{1}^{2}=3-2\ln{(2)}$
		\pr{(d)} Let $Y=h(X)$ be the left amt. Then $h(x)=1.5-x$ if $x<1.5$, otherwise $h(x)=0$.
			So $E(Y)=E(h(X)) = \int_{1}^{2}h(x)f(x)dx=\int_{1}^{1.5}(1.5-x)2(1-x^{-2})dx
				= 2\int_{1}^{1.5}(1.5-x-1.5/x^{2}+1/x)dx
				=2(1.5\times 0.5 -(1.5^{2}-1)/2 - 1.5\times (1-1/1.5) + \ln{1.5})=0.061$	
	
	
	\pagebreak
	% SHORTCUTS
	\re{V(X)=} $E(X^{2})-(E(X))^{2}$
	\re{$\sigma =$}$\sqrt{V(X)}$
	
	
\end{document}